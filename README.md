# [CongressTweets](http://www.cotustweets.info)

### Why CongressTweets? 
##### Twitter has very rapidly become a way for elected officials to interact with their constituents. However, following the entire body of the US Congress on Twitter would expose an individual to too much information. Additionally, Congresspeople on Twitter are, at the end of the day, still just people on Twitter and not everything they tweet is of great importance (e.g., when their favorite sports team wins). That said, these individuals discuss important things using this platform. Things like healthcare and tax reform, things that can impact millions of lives. Taking all of this information and distilling it down to five significant topics saves a user of this site a substantial amount of time and allows them to stay in the loop in a matter of minutes. Finally, a user can quickly see if their own representatives are engaging with these topics and respond accordingly.

### How does it work?
##### Behind the scenes, Congress Tweets relies on an unsupervised natural language processing algorithm known as Latent Dirichlet Allocation (LDA). LDA is a generative statistical model that identifies topics in a body of texts (or tweets) based on how often words occur together. For this project, the LDA identifies which words tend to be associated with each topic and which topics are associated with each tweet. LDA is an incredibly useful tool, but has a number of limitations that make it challenging to use. Most notably, the number of topics that it identifies must be specified by the user prior to running the model.

##### The goal of Congress Tweets is to provide a summary of the five most significant topics from the last seven days, however this does not mean that the LDA is simply asked for five topics each day. Instead, every morning, Congress Tweets takes all of the tweets from the past week and dynamically selects an optimal number of topics to model. 

##### In order to do this, the entire set of tweets is split into a training set and a testing set and an initial LDA model is trained using 5 topics. Next, each tweet in the test set is split in half and fed back into the trained model (i.e., we ask the model to guess which topic the first half of a tweet belongs to and which topic the second half of a tweet belongs to). Finally, using a technique known as cosine similarity, the topic assignments for the first half of the test tweets are compared to the topic assignments for the second half of the test tweets. Put differently, we are looking for our model to be consistent, and this is a way to test this consistency. After this cycle is completed, the model is trained again for a greater number of topics and goes through these steps again. After trying a range of topics between 5 and 30, the topic size that is the most consistent (i.e., the one with the highest cosine similarity) is selected as our optimal topic number for that day, and the LDA is trained one final time using all of the tweets from the week.

##### From the final trained model, the top five topics are selected and summarized so a user can see what the topics are, who is tweeting about them, how this topic trended over the last week, and how the different politcal parties engaged in these conversations.
