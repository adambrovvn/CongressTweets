{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import requests\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "from pandas.io.json import json_normalize\n",
    "from urllib.request import urlopen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set dates to define week of data\n",
    "in_date=pd.datetime.today()-timedelta(days=1)\n",
    "start=in_date - timedelta(days=6)\n",
    "in_date=in_date.strftime('%Y-%m-%d')\n",
    "start=start.strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "date_list=pd.date_range(start, in_date, freq='D')\n",
    "date_list=date_list.strftime('%Y-%m-%d')\n",
    "date_list=date_list.astype(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "#generate urls for each date in model\n",
    "url_list=[]\n",
    "for i in date_list:\n",
    "    istr=str(i)\n",
    "    url='https://raw.githubusercontent.com/alexlitel/congresstweets/master/data/'+istr+'.json'\n",
    "    url_list.append(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#read in data\n",
    "df_from_each_file = (pd.read_json(u) for u in url_list)\n",
    "full=pd.concat(df_from_each_file, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#datetime conversion\n",
    "full['dtime']=pd.to_datetime(full.time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get users file\n",
    "usersurl='https://raw.githubusercontent.com/alexlitel/congresstweets-automator/master/data/users-filtered.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "users=urlopen(usersurl).read()\n",
    "users_dict=json.loads(users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#extract office and campaign twitter handles\n",
    "office = []\n",
    "campaign = []\n",
    "for j in range(0,len(users_dict)):\n",
    "    try:\n",
    "        if users_dict[j]['accounts'][0]['account_type']=='office':\n",
    "            office.append(users_dict[j]['accounts'][0]['screen_name'])   \n",
    "        elif users_dict[j]['accounts'][1]['account_type']=='office':\n",
    "            office.append(users_dict[j]['accounts'][1]['screen_name'])\n",
    "        elif users_dict[j]['accounts'][2]['account_type']=='office':\n",
    "            office.append(users_dict[j]['accounts'][2]['screen_name'])\n",
    "    except:\n",
    "        office.append('empty')\n",
    "    try:\n",
    "        if users_dict[j]['accounts'][1]['account_type']=='campaign':\n",
    "            campaign.append(users_dict[j]['accounts'][1]['screen_name'])\n",
    "        elif users_dict[j]['accounts'][2]['account_type']=='campaign':\n",
    "            campaign.append(users_dict[j]['accounts'][2]['screen_name'])\n",
    "        elif users_dict[j]['accounts'][3]['account_type']=='campaign':\n",
    "            campaign.append(users_dict[j]['accounts'][3]['screen_name'])\n",
    "        elif users_dict[j]['accounts'][0]['account_type']=='campaign':\n",
    "            campaign.append(users_dict[j]['accounts'][0]['screen_name'])\n",
    "        elif users_dict[j]['accounts'][4]['account_type']=='campaign':\n",
    "            campaign.append(users_dict[j]['accounts'][4]['screen_name'])\n",
    "    except:\n",
    "        campaign.append(\"empty\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(592, 7)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "handles=json_normalize(hand_dict)\n",
    "handles.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create df series for handles\n",
    "handles['officeSN']=office\n",
    "handles['campaignSN']=campaign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#combine tweets with congressperson identifying info and create final df for week\n",
    "temp1=pd.merge(full, handles, how='inner', left_on=['screen_name'], right_on=['officeSN'])\n",
    "temp2=pd.merge(full, handles, how='inner', left_on=['screen_name'], right_on=['campaignSN'])\n",
    "\n",
    "final = pd.concat([temp1,temp2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#drop non individual twitter handles e.g. cloakroom handles\n",
    "final=final[final.type=='member']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final=final.drop(['time'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final.text=final.text.str.lower()\n",
    "final.text=final.text.str.replace('\\n','')\n",
    "final.text=final.text.str.replace('.','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11359, 17)"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fin.to_csv('tweet_save'+in_date+'.csv',date_format='%Y-%m-%d %H:%M:%S')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
